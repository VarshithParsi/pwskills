{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61bc9c6a",
   "metadata": {},
   "source": [
    "Question 1: What is Logistic Regression, and how does it differ from Linear Regression?\n",
    "\n",
    "Answer: Logistic Regression is a statistical method used for binary classification problems, where the output is categorical (e.g., yes/no, true/false). It models the probability that a given input belongs to a particular category using the Sigmoid function.\n",
    "\n",
    "Differences from Linear Regression:\n",
    "\n",
    "Output: Linear Regression predicts continuous values; Logistic Regression predicts probabilities between 0 and 1.\n",
    "Function Used: Linear uses a straight-line equation; Logistic uses the Sigmoid function.\n",
    "Application: Linear is used for regression tasks; Logistic is used for classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6522ef69",
   "metadata": {},
   "source": [
    "Question 2: Explain the role of the Sigmoid function in Logistic Regression.\n",
    "\n",
    "Answer:\n",
    "\n",
    "The Sigmoid function is a mathematical function used in Logistic Regression to convert the output of a linear equation into a probability value between 0 and 1. This makes it ideal for binary classification tasks.\n",
    "\n",
    "Formula:\n",
    "\n",
    "The Sigmoid function is defined as:\n",
    "\n",
    "  σ(z) = 1 / (1 + e^(−z))\n",
    "\n",
    "Where:\n",
    "\n",
    "z = wᵀx + b\n",
    "w is the weight vector\n",
    "x is the input feature vector\n",
    "b is the bias term\n",
    "\n",
    "Role in Classification:\n",
    "\n",
    "The output of the Sigmoid function is interpreted as the probability that the input belongs to the positive class. A threshold (commonly 0.5) is applied:\n",
    "\n",
    "If σ(z) ≥ 0.5, classify as positive\n",
    "If σ(z) < 0.5, classify as negative\n",
    "This enables Logistic Regression to make decisions based on probability rather than raw scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102acb0f",
   "metadata": {},
   "source": [
    "Question 3: What is Regularization in Logistic Regression and why is it needed?\n",
    "\n",
    "Answer: Regularization is a technique used to prevent overfitting by penalizing large coefficients in the model. In Logistic Regression, L1 (Lasso) and L2 (Ridge) regularization are commonly used.\n",
    "\n",
    "L1 encourages sparsity (some coefficients become zero).\n",
    "L2 discourages large weights but doesn’t eliminate them.\n",
    "It helps improve generalization and model performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831ef9f",
   "metadata": {},
   "source": [
    "Question 4: What are some common evaluation metrics for classification models, and why are they important?\n",
    "\n",
    "Answer: Common metrics include:\n",
    "\n",
    "Accuracy: Proportion of correct predictions.\n",
    "Precision: True positives / (True positives + False positives).\n",
    "Recall: True positives / (True positives + False negatives).\n",
    "F1 Score: Harmonic mean of precision and recall.\n",
    "ROC-AUC: Measures the ability to distinguish between classes.\n",
    "These metrics help assess model performance beyond simple accuracy, especially in imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c96d4dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Question 5: Python program to train Logistic Regression and print accuracy.\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b590bf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [[-0.39347744  0.96248927 -2.37513361 -0.99874691]\n",
      " [ 0.50844553 -0.2548109  -0.21300984 -0.77574616]\n",
      " [-0.11496809 -0.70767836  2.58814346  1.77449307]]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Question 6: Train a Logistic Regression model using L2 regularization (Ridge) and print the model coefficients and accuracy.\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model (no need to set multi_class)\n",
    "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Output\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6e7ad60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Question 7: Train Logistic Regression for multiclass classification using multi_class='ovr'.\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Wrap Logistic Regression in OneVsRestClassifier\n",
    "model = OneVsRestClassifier(LogisticRegression(solver='lbfgs', max_iter=200))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and report\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "236ecea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Validation Accuracy: 0.9666666666666666\n"
     ]
    }
   ],
   "source": [
    "#Question 8: Apply GridSearchCV to tune C and penalty.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid (only 'l2' is supported by 'lbfgs')\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs']\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=200), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Output best parameters and score\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Validation Accuracy:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b50c03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without scaling: 1.0\n",
      "Accuracy with scaling: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Question 9: Standardize features before training and compare accuracy.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Without scaling\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy without scaling:\", accuracy_score(y_test, model.predict(X_test)))\n",
    "\n",
    "# With scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model_scaled = LogisticRegression()\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "print(\"Accuracy with scaling:\", accuracy_score(y_test, model_scaled.predict(X_test_scaled)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da873c2",
   "metadata": {},
   "source": [
    "Question 10: Approach for imbalanced dataset in marketing campaign prediction.\n",
    "\n",
    "Answer:\n",
    "\n",
    "Data Handling:\n",
    "\n",
    "Use techniques like SMOTE or undersampling to balance classes.\n",
    "Handle missing values and outliers.\n",
    "Feature Scaling:\n",
    "\n",
    "Apply standardization or normalization to ensure features are on the same scale.\n",
    "Balancing Classes:\n",
    "\n",
    "Use class weights in Logistic Regression (class_weight='balanced').\n",
    "Hyperparameter Tuning:\n",
    "\n",
    "Use GridSearchCV to find optimal C, penalty, and solver.\n",
    "Evaluation:\n",
    "\n",
    "Use metrics like Precision, Recall, F1 Score, and ROC-AUC.\n",
    "Confusion matrix to understand false positives/negatives.\n",
    "This approach ensures the model is robust and effective for real-world business decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
